{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --quiet pyvi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nampham/anaconda3/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "from pyvi import ViTokenizer\n",
    "from tqdm.contrib.concurrent import thread_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageName</th>\n",
       "      <th>VietnameseName</th>\n",
       "      <th>EnglishName</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>001.jpeg</td>\n",
       "      <td>COMBO 1</td>\n",
       "      <td>COMBO 1</td>\n",
       "      <td>169000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>001.jpeg</td>\n",
       "      <td>COMBO 2</td>\n",
       "      <td>COMBO 2</td>\n",
       "      <td>169000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>001.jpeg</td>\n",
       "      <td>COMBO 3</td>\n",
       "      <td>COMBO 3</td>\n",
       "      <td>169000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>001.jpeg</td>\n",
       "      <td>RƯỢU SOJU</td>\n",
       "      <td>SOJU</td>\n",
       "      <td>NOT GIVEN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>001.jpeg</td>\n",
       "      <td>RƯỢU VODKA</td>\n",
       "      <td>VODKA</td>\n",
       "      <td>NOT GIVEN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ImageName VietnameseName EnglishName      Price\n",
       "0  001.jpeg        COMBO 1     COMBO 1     169000\n",
       "1  001.jpeg        COMBO 2     COMBO 2     169000\n",
       "2  001.jpeg        COMBO 3     COMBO 3     169000\n",
       "3  001.jpeg      RƯỢU SOJU        SOJU  NOT GIVEN\n",
       "4  001.jpeg     RƯỢU VODKA       VODKA  NOT GIVEN"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATAPATH = \"/Users/nampham/OneDrive - Đại học FPT- FPT University/Intern/Menu/label data/labels.xlsx\"\n",
    "df = pd.read_excel(DATAPATH)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['COMBO 1' 'COMBO 2' 'COMBO 3' ... 'CÁ SƠN NƯỚNG' 'CÁ CHỈ VÀNG'\n",
      " 'CÁ LAO NƯỚNG ']\n"
     ]
    }
   ],
   "source": [
    "food_names = df['VietnameseName'].values\n",
    "print(food_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['belgian', 'dark', 'ibu', 'phở', 'đùi', 'trứng', 'non', 'hải', 'sản', 'xuân']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean_food_name(food_name):\n",
    "    #Remove quantity for example 500ML 1L 20KG ....\n",
    "    food_name = food_name.lower()\n",
    "    food_name = re.sub(r'\\d+\\w+', ' ', food_name)\n",
    "    #Remove purification and digits\n",
    "    food_name = re.sub(r\"[^\\w\\s]|\\d\", ' ', food_name)\n",
    "    #Remove size entites\n",
    "    token = r\"\\s+x{0,2}[xlms][\\.:-]?\\b|(nhỏ|vừa|lớn|bự|to|small|medium|big|large):?\"\n",
    "    food_name = re.sub(token, \" \", food_name)\n",
    "    #Remove specail token\n",
    "    food_name = re.sub(r\"_x\", ' ', food_name)\n",
    "    \n",
    "    food_name = food_name.strip().split()\n",
    "    return food_name\n",
    "    \n",
    "\n",
    "test = clean_food_name('BELGIAN DARK 8.1%/IBU 32 -    X 500ML (PHỞ ĐÙI + TRỨNG NON) X L M nhỏ vừa_x hải sản xuân')\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['belgian dark', 'dark ibu', 'ibu phở', 'phở đùi', 'đùi trứng', 'trứng non', 'non hải', 'hải sản']\n"
     ]
    }
   ],
   "source": [
    "def get_big_gram(text, n=2, m=2):\n",
    "    words = clean_food_name(text)\n",
    "    big_grams = []\n",
    "    \n",
    "    for k in range(n,m+1):\n",
    "        for i in range(len(words)):\n",
    "            big_gram = ''\n",
    "            if i + k > len(words):\n",
    "                continue\n",
    "            \n",
    "            for j in range(k):\n",
    "                big_gram += words[i+j] + ' '\n",
    "                \n",
    "            big_grams.append(big_gram.strip())\n",
    "            \n",
    "    return big_grams\n",
    "\n",
    "print(get_big_gram('BELGIAN DARK 8.1%/IBU 32 - 500ML (PHỞ ĐÙI + TRỨNG NON) hải sản'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15211/15211 [00:00<00:00, 848872.48it/s]\n",
      "100%|██████████| 15211/15211 [00:00<00:00, 822742.38it/s]\n"
     ]
    }
   ],
   "source": [
    "food_vocabulary = thread_map(clean_food_name, food_names, max_workers=6)\n",
    "food_vocabulary_big_grams = thread_map(get_big_gram, food_names, max_workers=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['combo', 'combo', 'combo', 'rượu', 'soju', 'rượu', 'vodka', 'tiger', 'lon', 'tiger']\n"
     ]
    }
   ],
   "source": [
    "food_vocabulary = [item for sublist in food_vocabulary for item in sublist]\n",
    "print(food_vocabulary[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['rượu soju', 'rượu vodka', 'tiger lon', 'tiger chai', 'tiger bạc', 'bạc chai', 'tiger bạc', 'bạc lon', 'bò húc', 'bia quy', 'quy nhơn', 'bia bivina', 'strong bow', 'rau muống', 'muống xào', 'xào tỏi', 'mồng tơi', 'tơi xào', 'xào tỏi', 'cải xào']\n"
     ]
    }
   ],
   "source": [
    "food_vocabulary_big_grams = [item for sublist in food_vocabulary_big_grams for item in sublist]\n",
    "print(food_vocabulary_big_grams[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save corpus\n",
    "with open('food_vocabulary_tokenize.txt', 'w', encoding='utf-8') as f:\n",
    "    for food, count in corpus.most_common():\n",
    "        save_format = f\"{food}${count}\\n\"\n",
    "        f.write(save_format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('cá', 1513),\n",
       " ('trà', 1312),\n",
       " ('nướng', 1174),\n",
       " ('sữa', 1117),\n",
       " ('chiên', 1053),\n",
       " ('bò', 1014),\n",
       " ('xào', 823),\n",
       " ('gà', 779),\n",
       " ('tôm', 710),\n",
       " ('cơm', 620)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "corpus = Counter(food_vocabulary)\n",
    "corpus.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('trà sữa', 472),\n",
       " ('hải sản', 374),\n",
       " ('phô mai', 322),\n",
       " ('trân châu', 252),\n",
       " ('cơm chiên', 245),\n",
       " ('cá hồi', 240),\n",
       " ('sữa chua', 212),\n",
       " ('chiên mắm', 177),\n",
       " ('thập cẩm', 166),\n",
       " ('muối ớt', 161)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_big_grams = Counter(food_vocabulary_big_grams)\n",
    "corpus_big_grams.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save corpus\n",
    "with open('food_vocabulary.txt', 'w', encoding='utf-8') as f:\n",
    "    for food, count in corpus.most_common():\n",
    "        if count > 1:\n",
    "            save_format = f\"{food}${count}\\n\"\n",
    "            f.write(save_format)\n",
    "\n",
    "with open('food_vocabulary_big_grams.txt', 'w', encoding='utf-8') as f:\n",
    "    for food, count in corpus_big_grams.most_common():\n",
    "        if count > 1:\n",
    "            save_format = f\"{food}${count}\\n\"\n",
    "            f.write(save_format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import symspellpy\n",
    "import random\n",
    "\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'BLIAN DARK 8.1%IU 32 -500MLPHỞ ĐÙI + TRỨNG NO)'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def random_delete(text, percent = 0.1):\n",
    "    n = int(percent*len(text))+1\n",
    "    text_aggumented = list(text)\n",
    "    \n",
    "    for i in range(n):\n",
    "        k = random.randint(0, len(text_aggumented)-1)\n",
    "        del text_aggumented[k]\n",
    "        \n",
    "    return \"\".join(text_aggumented)\n",
    "\n",
    "def random_replace(text, percent = 0.2):\n",
    "    n = int(percent*len(text))+1\n",
    "    text_aggumented = list(text)\n",
    "    \n",
    "    for i in range(n):\n",
    "        k = -1\n",
    "        while k == -1 or text[k] == ' ':\n",
    "            k = random.randint(0, len(text)-1)\n",
    "\n",
    "        char = random.choice(string.ascii_uppercase)\n",
    "        text_aggumented[k] = char\n",
    "        \n",
    "    return \"\".join(text_aggumented)\n",
    "\n",
    "def random_swap(text, percent = 0.1):\n",
    "    n = int(percent*len(text))+1\n",
    "    text_aggumented = list(text)\n",
    "    \n",
    "    for i in range(n):\n",
    "        k = -1\n",
    "        while k == -1 or text[k] == ' ':\n",
    "            k = random.randint(0, len(text)-1)\n",
    "        h = k\n",
    "        while h == k or text[h] == ' ':\n",
    "            h = random.randint(0, len(text)-1)\n",
    "        text_aggumented[k], text_aggumented[h] = text_aggumented[h], text_aggumented[k]\n",
    "        \n",
    "    return \"\".join(text_aggumented)\n",
    "\n",
    "def lower(text):\n",
    "    text = text.lower()\n",
    "    return text\n",
    "\n",
    "def random_text_aggument(text):\n",
    "    k = random.randint(0, 2)\n",
    "    random_agg = {0: random_delete, 1:random_replace, 2:random_swap}\n",
    "    return random_agg[k](text, percent=0.125)\n",
    "    \n",
    "random_text_aggument('BELGIAN DARK 8.1%IBU 32 - 500ML (PHỞ ĐÙI + TRỨNG NON)')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:00<00:00, 430715.14it/s]\n",
      "100%|██████████| 500/500 [00:00<00:00, 530387.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['nước ép cà rốt', 'lẩu đuôi bò', 'nem chua rán', 'sake dassai (720ml)', 'dồi rán', 'bò húc ', 'sô cô la']\n",
      "['ưc ép cà rốt', 'lẩu đôui bò', 'nem AhDa rán', 'sakG daAsaF (720ml)', 'dồi rá', 'ò húc ', 'sô Jô la']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "TEST_CASE = random.choices(food_names, k = 500)\n",
    "TEST_CASE = thread_map(lower, TEST_CASE, max_workers=6)\n",
    "TEST_CASE_WRONG = thread_map(random_text_aggument, TEST_CASE, max_workers=6)\n",
    "\n",
    "print(TEST_CASE[:7])\n",
    "print(TEST_CASE_WRONG[:7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.967741935483871\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def cer(pred, true):\n",
    "    n = len(true)\n",
    "    wrong = 0\n",
    "    for c1, c2 in zip(pred, true):\n",
    "        if c1 != c2:\n",
    "            wrong += 1\n",
    "    \n",
    "    \n",
    "    return (n - wrong)/n\n",
    "\n",
    "def wer(pred, true):\n",
    "    pred = pred.split()\n",
    "    true = true.split()\n",
    "    n = len(true)\n",
    "    wrong = 0\n",
    "    for c1, c2 in zip(pred, true):\n",
    "        if c1 != c2:\n",
    "            wrong += 1\n",
    "    \n",
    "    return (n - wrong)/n\n",
    "\n",
    "print(cer(\"tomorrow now today and tomorrow\", \"tomorrow now today and tomoraow\"))\n",
    "wer(\"tomorrow now today and tomorrow\", \"tomorrow now today and tomoraow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('cá', 1513), ('trà', 1312), ('nướng', 1174), ('sữa', 1117), ('chiên', 1053)]\n",
      "[('trà sữa', 472), ('hải sản', 374), ('phô mai', 322), ('trân châu', 252), ('cơm chiên', 245)]\n"
     ]
    }
   ],
   "source": [
    "from symspellpy import SymSpell, Verbosity\n",
    "from itertools import islice\n",
    "import numpy as np\n",
    "\n",
    "EDIT_DISTANCE = 3\n",
    "\n",
    "spell_check = SymSpell(max_dictionary_edit_distance=EDIT_DISTANCE)\n",
    "spell_check.load_dictionary('food_vocabulary.txt', 0, 1, \n",
    "                                    encoding='utf-8', separator='$')\n",
    "spell_check.load_bigram_dictionary('food_vocabulary_big_grams.txt', 0, 1, \n",
    "                                    encoding='utf-8', separator='$')\n",
    "\n",
    "print(list(islice(spell_check.words.items(), 5)))\n",
    "print(list(islice(spell_check.bigrams.items(), 5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_spell(text):\n",
    "    import re \n",
    "    \n",
    "    text = re.sub(r'[.\\?#@+,<>%~`!$^&\\(\\):;\\\\\\/]', r' \\g<0> ', text)\n",
    "    \n",
    "    suggestion = spell_check.lookup_compound(text, max_edit_distance=EDIT_DISTANCE,\n",
    "                                             ignore_non_words=True, ignore_term_with_digits=True)\n",
    "    \n",
    "    return suggestion[0]._term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example: \n",
      "['nước ép cà rốt', 'lẩu đuôi bò', 'nem chua rán', 'sake dassai (720ml)', 'dồi rán', 'bò húc ', 'sô cô la']\n",
      "['ưc ép cà rốt', 'lẩu đôui bò', 'nem AhDa rán', 'sakG daAsaF (720ml)', 'dồi rá', 'ò húc ', 'sô Jô la']\n",
      "['ốc ép cà rốt', 'lẩu đuôi bò', 'nem a da rán', 'sake dassai 720ml', 'dồi cá', 'bò húc', 'sô ô la']\n",
      "Metric: WER: 0.677 CER: 0.725\n",
      "CPU times: user 380 ms, sys: 5.4 ms, total: 386 ms\n",
      "Wall time: 391 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "test_result = []\n",
    "wer_result = []\n",
    "cer_result = []\n",
    "N = 7\n",
    "for test_case, val in zip(TEST_CASE_WRONG, TEST_CASE):\n",
    "    correct_text = correct_spell(test_case)\n",
    "    \n",
    "    test_result.append(correct_text)\n",
    "        \n",
    "        \n",
    "    wer_result.append(\n",
    "        wer(correct_text, val)\n",
    "    )\n",
    "    \n",
    "    cer_result.append(\n",
    "        cer(correct_text, val)\n",
    "    )\n",
    "    \n",
    "\n",
    "print(\"Example: \")\n",
    "print(TEST_CASE[:N])\n",
    "print(TEST_CASE_WRONG[:N])\n",
    "print(test_result[:N])\n",
    "\n",
    "print(\"Metric:\", f\"WER: {np.mean(wer_result):.3f}\", f\"CER: {np.mean(cer_result):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'nước ép cà rốt'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_spell(\"nuoc ep cà rốt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
